{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbutori/autoestudo-ccm10s06/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdHRpb069Vpf"
      },
      "source": [
        "# Treinamento: Classificação de Imagens (CIFAR-10)\n",
        "\n",
        "Esse notebook treina o modelo e gera um arquivo `cifar_net.pth` ao final, que pode ser usado por nossa API em Flask."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbrOKv9Y9Vpg"
      },
      "source": [
        "## Importar bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cLlUcqFl9Vph"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38RVBOzM9Vph"
      },
      "source": [
        "\n",
        "## Definir transformações para data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hha_bkZf9Vph"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomCrop(32, padding=4),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAxTAPT09Vpi"
      },
      "source": [
        "## Carregar dados CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRSb9UJ9Vpi",
        "outputId": "9bee6f9f-7ed7-4627-e294-2c43b6031ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43778199.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j66a73DV9Vpi"
      },
      "source": [
        "## Definir a rede neural"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "tt3gaHz39ttk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LerDb1ax9Vpi"
      },
      "source": [
        "\n",
        "## Definir função de perda e otimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eMIrH_XX9Vpi"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrWUiIGS9Vpi"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQsigNr89Vpi",
        "outputId": "426321fc-b7ee-4d80-e8bb-f83b95a5e827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Época 1, Perda do Batch 100]: 2.307\n",
            "[Época 1, Perda do Batch 200]: 2.304\n",
            "[Época 1, Perda do Batch 300]: 2.303\n",
            "[Época 1, Perda do Batch 400]: 2.303\n",
            "[Época 1, Perda do Batch 500]: 2.302\n",
            "[Época 2, Perda do Batch 100]: 2.302\n",
            "[Época 2, Perda do Batch 200]: 2.300\n",
            "[Época 2, Perda do Batch 300]: 2.298\n",
            "[Época 2, Perda do Batch 400]: 2.294\n",
            "[Época 2, Perda do Batch 500]: 2.288\n",
            "[Época 3, Perda do Batch 100]: 2.277\n",
            "[Época 3, Perda do Batch 200]: 2.264\n",
            "[Época 3, Perda do Batch 300]: 2.246\n",
            "[Época 3, Perda do Batch 400]: 2.236\n",
            "[Época 3, Perda do Batch 500]: 2.211\n",
            "[Época 4, Perda do Batch 100]: 2.194\n",
            "[Época 4, Perda do Batch 200]: 2.176\n",
            "[Época 4, Perda do Batch 300]: 2.160\n",
            "[Época 4, Perda do Batch 400]: 2.150\n",
            "[Época 4, Perda do Batch 500]: 2.138\n",
            "[Época 5, Perda do Batch 100]: 2.123\n",
            "[Época 5, Perda do Batch 200]: 2.118\n",
            "[Época 5, Perda do Batch 300]: 2.104\n",
            "[Época 5, Perda do Batch 400]: 2.081\n",
            "[Época 5, Perda do Batch 500]: 2.068\n",
            "[Época 6, Perda do Batch 100]: 2.055\n",
            "[Época 6, Perda do Batch 200]: 2.039\n",
            "[Época 6, Perda do Batch 300]: 2.024\n",
            "[Época 6, Perda do Batch 400]: 2.021\n",
            "[Época 6, Perda do Batch 500]: 1.997\n",
            "[Época 7, Perda do Batch 100]: 1.977\n",
            "[Época 7, Perda do Batch 200]: 1.969\n",
            "[Época 7, Perda do Batch 300]: 1.952\n",
            "[Época 7, Perda do Batch 400]: 1.934\n",
            "[Época 7, Perda do Batch 500]: 1.912\n",
            "[Época 8, Perda do Batch 100]: 1.898\n",
            "[Época 8, Perda do Batch 200]: 1.887\n",
            "[Época 8, Perda do Batch 300]: 1.887\n",
            "[Época 8, Perda do Batch 400]: 1.869\n",
            "[Época 8, Perda do Batch 500]: 1.850\n",
            "[Época 9, Perda do Batch 100]: 1.841\n",
            "[Época 9, Perda do Batch 200]: 1.831\n",
            "[Época 9, Perda do Batch 300]: 1.854\n",
            "[Época 9, Perda do Batch 400]: 1.831\n",
            "[Época 9, Perda do Batch 500]: 1.815\n",
            "[Época 10, Perda do Batch 100]: 1.811\n",
            "[Época 10, Perda do Batch 200]: 1.809\n",
            "[Época 10, Perda do Batch 300]: 1.808\n",
            "[Época 10, Perda do Batch 400]: 1.793\n",
            "[Época 10, Perda do Batch 500]: 1.790\n",
            "Treinamento Encerrado\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Época {epoch + 1}, Perda do Batch {i + 1}]: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Treinamento Encerrado')\n",
        "torch.save(net.state_dict(), 'cifar_net.pth')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}